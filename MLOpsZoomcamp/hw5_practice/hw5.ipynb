{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Prepare the dataset\n",
    "\n",
    "Start with `baseline_model_nyc_taxi_data.ipynb`. Download the March 2023 Green Taxi data. We will use this data to simulate a production usage of a taxi trip duration prediction service.\n",
    "\n",
    "What is the shape of the downloaded data? How many rows are there?\n",
    "\n",
    "* 72044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [('green_tripdata_2023-03.parquet', 'data')]\n",
    "\n",
    "print(\"Download files:\")\n",
    "for file, path in files:\n",
    "    url=f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file}\"\n",
    "    resp=requests.get(url, stream=True)\n",
    "    save_path=f\"{path}/{file}\"\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        for data in tqdm(resp.iter_content(),\n",
    "                        desc=f\"{file}\",\n",
    "                        postfix=f\"save to {save_path}\",\n",
    "                        total=int(resp.headers[\"Content-Length\"])):\n",
    "            handle.write(data)\n",
    "\n",
    "mar_data = pd.read_parquet('./data/green_tripdata_2023-03.parquet')\n",
    "mar_data.describe()\n",
    "mar_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Metric\n",
    "\n",
    "Let's expand the number of data quality metrics we’d like to monitor! Please add one metric of your choice and a quantile value for the `\"fare_amount\"` column (`quantile=0.5`).\n",
    "\n",
    "Hint: explore evidently metric `ColumnQuantileMetric` (from `evidently.metrics import ColumnQuantileMetric`) \n",
    "\n",
    "What metric did you choose?\n",
    "- DatasetCorrelationsMetric()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric\n",
    "from evidently.metrics import ColumnQuantileMetric\n",
    "from evidently.metrics import DatasetCorrelationsMetric\n",
    "\n",
    "report = Report(metrics=[\n",
    "    ColumnDriftMetric(column_name='prediction'),\n",
    "    DatasetDriftMetric(),\n",
    "    DatasetMissingValuesMetric(),\n",
    "    DatasetCorrelationsMetric(),\n",
    "    ColumnQuantileMetric(column_name='fare_amount', quantile=0.5),\n",
    "]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Prefect flow \n",
    "\n",
    "Let’s update prefect tasks by giving them nice meaningful names, specifying a number of delays and retries.\n",
    "\n",
    "Hint: use `evidently_metrics_calculation.py` script as a starting point to implement your solution. Check the  prefect docs to check task parameters.\n",
    "\n",
    "What is the correct way of doing that?\n",
    "\n",
    "* `@task(retries=2, retry_delay_seconds=5, name=\"calculate metrics\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(retries=2, retry_delay_seconds=5, name = \"calculate metrics\")\n",
    "def calculate_metrics_postgresql(curr, i):\n",
    "\tcurrent_data = raw_data[(raw_data.lpep_pickup_datetime >= (begin + datetime.timedelta(i))) &\n",
    "\t\t(raw_data.lpep_pickup_datetime < (begin + datetime.timedelta(i + 1)))]\n",
    "\n",
    "\t#current_data.fillna(0, inplace=True)\n",
    "\tcurrent_data['prediction'] = model.predict(current_data[num_features + cat_features].fillna(0))\n",
    "\n",
    "\treport.run(reference_data = reference_data, current_data = current_data,\n",
    "\t\tcolumn_mapping=column_mapping)\n",
    "\n",
    "\tresult = report.as_dict()\n",
    "\n",
    "\tprediction_drift = result['metrics'][0]['result']['drift_score']\n",
    "\tnum_drifted_columns = result['metrics'][1]['result']['number_of_drifted_columns']\n",
    "\tshare_missing_values = result['metrics'][2]['result']['current']['share_of_missing_values']\n",
    "\tpearson_value = result['metrics'][3]['result']['current']['stats']['pearson']['abs_max_correlation']\n",
    "\tquantile_value = result['metrics'][4]['result']['current']['value']\n",
    "\n",
    "\tcurr.execute(\n",
    "\t\t\"insert into dummy_metrics(timestamp, prediction_drift, num_drifted_columns, share_missing_values, pearson_value, quantile_value) values (%s, %s, %s, %s, %s, %s)\",\n",
    "\t\t(begin + datetime.timedelta(i), prediction_drift, num_drifted_columns, share_missing_values, pearson_value, quantile_value)\n",
    "\t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Monitoring\n",
    "\n",
    "Let’s start monitoring. Run expanded monitoring for a new batch of data (March 2023). \n",
    "\n",
    "What is the maximum value of metric `quantile = 0.5` on th `\"fare_amount\"` column during March 2023 (calculated daily)?\n",
    "\n",
    "* 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"Q4.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Dashboard\n",
    "\n",
    "\n",
    "Finally, let’s add panels with new added metrics to the dashboard. After we customize the  dashboard lets save a dashboard config, so that we can access it later. Hint: click on “Save dashboard” to access JSON configuration of the dashboard. This configuration should be saved locally.\n",
    "\n",
    "Where to place a dashboard config file?\n",
    "\n",
    "* `project_folder/dashboards`  (05-monitoring/dashboards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume ? ??\n",
      "Volume serial number is 3099-9011\n",
      "D:\\CODE\\GITHUBLAWN\\MLOPSZOOMCAMP\\HW5_PRACTICE\\DASHBOARDS\n",
      "    data_drift.json\n",
      "    \n",
      "No subfolders exist \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tree dashboards /F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
